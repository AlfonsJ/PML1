{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas de clasificación\n",
    "\n",
    "En los problemas de clasificación asumimos que los estados de la naturaleza y acciones son etiquetas de clase:\n",
    "$$\\mathcal{H}=\\mathcal{Y}=\\{1,\\dotsc,C\\}\\qquad\\text{y}\\qquad\\mathcal{A}=\\mathcal{Y}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pérdida 01\n",
    "\n",
    "La pérdida 01 para dos clases, $\\mathcal{Y}=\\{0,1\\}$, aunque directamente generalizable, es:\n",
    "$$\\ell_{01}(y^*,\\hat{y})=\\left[%\n",
    "\\begin{array}{c|cc}\n",
    "    & \\hat{y}=0 & \\hat{y}=1\\\\\\hline%\n",
    "    y^*=0 & 0 & 1\\\\%\n",
    "    y^*=1 & 1 & 0\n",
    "\\end{array}\\right]=\\;\\mathbb{I}(y^*\\neq\\hat{y})$$\n",
    "La **pérdida esperada a posteriori** es la probabilidad de error a posteriori, esto es, uno menos la de acertar a posteriori:\n",
    "$$R(\\hat{y}\\mid\\boldsymbol{x})%\n",
    "=\\sum_y\\ell_{01}(y,\\hat{y})\\,p(y\\mid\\boldsymbol{x})\n",
    "=\\sum_{y\\neq\\hat{y}}p(y\\mid\\boldsymbol{x})\n",
    "=1-p(\\hat{y}\\mid\\boldsymbol{x})$$\n",
    "Claramente, el estimador de mínima pérdida esperada es el **estimador máximo a posteriori (MAP),** esto es, la etiqueta más probable o **moda** de la probabilidad a posteriori:\n",
    "$$\\pi(\\boldsymbol{x})=\\operatorname*{argmax}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$$ \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación sensible al coste\n",
    "\n",
    "Aunque la pérdida 01 es con mucho la más usada, en algunas aplicaciones conviene fijar costes distintos. Consideremos un problema de clasificación binario con función de pérdida general:\n",
    "$$\\ell(y^*,\\hat{y})=\\begin{pmatrix}\n",
    "\\ell_{00} & \\ell_{01}\\\\%\n",
    "\\ell_{10} & \\ell_{11}%\n",
    "\\end{pmatrix}$$\n",
    "Si $p_0=p(y^*=0\\mid\\boldsymbol{x})$ y $p_1=1-p_0$, debemos escoger $\\hat{y}=0$ si su riesgo es menor que el la clase $1$:\n",
    "$$\\ell_{00}\\,p_0+\\ell_{10}\\,p_1<\\ell_{01}\\,p_0+\\ell_{11}\\,p_1$$\n",
    "Si el coste de acertar es nulo, $\\ell_{00}=\\ell_{11}=0$, esta regla de decisión se simplifica como:\n",
    "$$\\ell_{10}\\,p_1<\\ell_{01}(1-p_1)\\quad\\to\\quad p_1<\\frac{\\ell_{01}}{\\ell_{01}+\\ell_{10}}$$\n",
    "Si, además, un falso negativo cuesta $c$ veces más que un falso positivo, $\\ell_{10}=c\\,\\ell_{01}$, entonces esta regla se simplifica aún más:\n",
    "$$p_1<\\frac{1}{1+c}$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación con opción de rechazo\n",
    "\n",
    "La inclusión de una **reject option** permite responder \"no sé\" cuando no se tiene una respuesta fiable. Para ello, si $\\mathcal{H}=\\mathcal{Y}=\\{1,\\dotsc,C\\}$ son los estados de la naturaleza, definimos una acción $0$ de rechazo y tomamos $\\mathcal{A}=\\mathcal{Y}\\cup\\{0\\}$. Supongamos que los aciertos tienen coste nulo, el rechazo un coste $\\lambda_r$, y que todos los errores de clasificación tienen un mismo coste $\\lambda_e>\\lambda_r$. Esto es, sea la función de pérdida:\n",
    "$$\\ell(y^*,a)=\\begin{cases}\n",
    "0 & \\text{si $a=y^*$}\\\\%\n",
    "\\lambda_r & \\text{si $a=0$}\\\\%\n",
    "\\lambda_e &\\text{en otro caso}%\n",
    "\\end{cases}$$\n",
    "El riesgo de predecir la clase $\\hat{y}$ es:\n",
    "$$R(\\hat{y}\\mid\\boldsymbol{x})%\n",
    "=\\sum_y\\ell(y,\\hat{y})\\,p(y\\mid\\boldsymbol{x})\n",
    "=\\sum_{y\\neq\\hat{y}}\\lambda_e\\,p(y\\mid\\boldsymbol{x})\n",
    "=\\lambda_e(1-p(\\hat{y}\\mid\\boldsymbol{x}))$$\n",
    "Así pues, al igual que con la pérdida 01, la clase de menor riesgo es la etiqueta más probable o **moda** de la probabilidad a posteriori:\n",
    "$$y^*=\\operatorname*{argmax}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$$ \n",
    "No obstante, clasificaremos solo si el riesgo de $y^*$ es menor que el de rechazo:\n",
    "$$\\lambda_e(1-p(y^*\\mid\\boldsymbol{x}))<\\lambda_r%\n",
    "\\quad\\to\\quad%\n",
    "p(y^*\\mid\\boldsymbol{x})>1-\\frac{\\lambda_r}{\\lambda_e}$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
