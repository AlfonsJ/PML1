{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.1a Conceptos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferencia Bayesiana:** $\\;$ cálculo de la **posterior** $p(H\\mid \\boldsymbol{x})$ mediante la regla de Bayes actualizar nuestras creencias sobre cantidades ocultas $H$ a partir de datos $\\boldsymbol{x}$\n",
    "\n",
    "**Teoría de la decisión Bayesiana:** $\\;$ usa la inferencia para decidir cuál es la mejor de las posibles **acciones** a realizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos básicos de la teoría de la decisión Bayesiana\n",
    "\n",
    "**Agente:** $\\;$ debe escoger una acción de un conjunto $\\mathcal{A}$\n",
    "\n",
    "**Estado de la naturaleza:** $\\;$ $h\\in\\mathcal{H}$, condiciona los costes y beneficios que se derivan de tomar cada acción posible\n",
    "\n",
    "**Función de pérdida:** $\\;$ indica el coste incurrido al tomar la acción $a\\in\\mathcal{A}$ cuando el estado de la naturaleza es $h\\in\\mathcal{H}$\n",
    "$$\\ell(h,a)$$\n",
    "\n",
    "**Riesgo (pérdida) esperado a posteriori:** $\\;$ de $a$ tras observar $\\boldsymbol{x}$\n",
    "$$R(a\\mid\\boldsymbol{x})=\\mathbb{E}_{p(h\\mid\\boldsymbol{x})}[\\ell(h,a)]%\n",
    "=\\sum_{h\\in\\mathcal{H}} \\ell(h,a)\\,p(h\\mid\\boldsymbol{x})$$\n",
    "\n",
    "**Política óptima o estimador de Bayes:** $\\;$ obtiene una acción de mínimo riesgo por cada observación posible\n",
    "$$\\pi^*(\\boldsymbol{x})=\\operatorname*{argmin}_{a\\in\\mathcal{A}}\\;R(a\\mid\\boldsymbol{x})$$\n",
    "\n",
    "**Función de utilidad:** $\\;$ deseabilidad de cada acción posible en cada posible estado, esto es, riesgo con signo cambiado\n",
    "$$U(h,a)=-\\ell(h,a)$$\n",
    "\n",
    "**Principio de utilidad esperada máxima:** $\\;$ estimador de Bayes expresado en términos de utilidad\n",
    "$$\\pi^*(\\boldsymbol{x})=\\operatorname*{argmax}_{a\\in\\mathcal{A}}\\;\\mathbb{E}_h[U(h,a)]$$\n",
    "\n",
    "**Sensibilidad al riesgo:** $\\;$ asumimos que el agente es **neutral,** esto es, insensible al riesgo, pero podría no ser así; por ejemplo, nos da igual obtener $50$ EUR con seguridad, o con $50\\%$ de probabilidad de $0$ y $100$ EUR"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
