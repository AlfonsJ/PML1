{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5.0 Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización\n",
    "\n",
    "**Sobre-entrenamiento (overfitting):** $\\;$ problema fundamental de MLE y, en general, ERM, asociado a la minimización de la pérdida sobre los datos de entrenamiento, ya que conduce a modelos **sobre-entrenados** que **no generalizan** (bien)\n",
    "\n",
    "**Ejemplo de overfitting:** $\\;$ probabilidad de obtener cara al lanzar una moneda\n",
    "* Lanzamos la moneda $N=3$ veces y obtenemos $3$ caras\n",
    "* El MLE es $\\,\\hat{\\theta}_{\\text{mle}}=N_1/(N_0+N_1)=3/(0+3)=1$\n",
    "* Si usamos $\\operatorname{Ber}(y\\mid\\hat{\\theta}_{\\text{mle}})$ para predecir, predeciremos cara en todos los lanzamientos futuros, cosa bastante inverosímil\n",
    "\n",
    "**Muchos parámetros suele conducir a overfitting:** $\\;$ ya que el modelo tiene suficientes parámetros para explicar los datos, por lo que acaba pareciéndose mucho a la empírica y no es capaz de generalizar\n",
    "\n",
    "**Regularización:** $\\;$ añade una **penalización (penalty)** a la pérdida mediante alguna forma de **penalización de complejidad** $C(\\boldsymbol{\\theta})$ cuyo peso depende de un **parámetro de regularización** $\\,\\lambda\\geq 0$\n",
    "$$\\mathcal{L}(\\boldsymbol{\\theta};\\lambda)=\\left[\\frac{1}{N}\\sum_n \\ell(\\boldsymbol{y}_n,\\boldsymbol{\\theta};\\boldsymbol{x}_n)\\right]+\\lambda\\,C(\\boldsymbol{\\theta})$$\n",
    "\n",
    "**Penalización de complejidad usual:** $\\;C(\\boldsymbol{\\theta})=-\\log p(\\boldsymbol{\\theta})\\,$ donde $p(\\boldsymbol{\\theta})$ es un **prior** más o menos plano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación maximum a posteriori (MAP)\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\hat{\\boldsymbol{\\theta}}_{\\text{map}}%\n",
    "&=\\operatorname*{argmax}_{\\boldsymbol{\\theta}}\\;\\log p(\\boldsymbol{\\theta}\\mid\\mathcal{D})%\n",
    "&&\\text{asumimos}\\quad p(\\boldsymbol{\\theta}\\mid\\mathcal{D})=\\delta(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}}_{\\text{map}})\\\\%\n",
    "&=\\operatorname*{argmax}_{\\boldsymbol{\\theta}}\\;\\log p(\\mathcal{D}\\mid\\boldsymbol{\\theta})+\\log p(\\boldsymbol{\\theta})\\\\\n",
    "&=\\operatorname*{argmin}_{\\boldsymbol{\\theta}}\\;-\\frac{1}{N}\\log p(\\mathcal{D}\\mid\\boldsymbol{\\theta})-\\frac{1}{N}\\log p(\\boldsymbol{\\theta})\\\\\n",
    "&=\\operatorname*{argmin}_{\\boldsymbol{\\theta}}\\;\\operatorname{NLL}(\\boldsymbol{\\theta})-\\lambda\\log p(\\boldsymbol{\\theta})%\n",
    "&&\\text{con log-pérdida y}\\,\\lambda=\\frac{1}{N}\n",
    "\\end{align*}$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
