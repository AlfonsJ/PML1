{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6.1 Representación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo gráfico probabilístico (PGM):** $\\;$ distribución de probabilidad conjunta que usa una estructura de grafo para codificar asunciones de independencia condicional\n",
    "\n",
    "**Red Bayesiana:** $\\;$ usa un **grafo acíclico dirigido (DAG)**\n",
    "\n",
    "**Representación:** $\\;$ cada nodo representa una variable aleatoria y cada ausencia de arista una independencia condicional\n",
    "\n",
    "**Orden topológico (DAG):** $\\;$ los nodos se numeran tal que cada nodo $Y_i$ sea condicionalmente independiente de todos sus predecesores no padres $\\mathbf{Y}_{\\operatorname{pred}(i)\\setminus\\operatorname{pa}(i)}$ dados sus padres $\\mathbf{Y}_{\\operatorname{pa}(i)}$\n",
    "\n",
    "**Distribución conjunta:** $\\;$ si $V$ es el número de nodos,\n",
    "$$p(\\mathbf{Y}_{1:V})=\\prod_{i=1}^Vp(Y_i\\mid\\mathbf{Y}_{\\operatorname{pa}(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1.1 Ejemplo: red de aspersores de agua\n",
    "\n",
    "**Variables:**\n",
    "* *Cloudy (C):* $\\;$ si es época de lluvias o no\n",
    "* *Rain (R):* $\\;$ si está lloviendo o no\n",
    "* *Sprinkler (S):* $\\;$ si los aspersores están en marcha o no\n",
    "* *Wet Grass (W):* $\\;$ si la hierba está húmeda o no\n",
    "\n",
    "**Dependencias condicionales:**\n",
    "* $C\\rightarrow R:$ $\\;$ en época de lluvias llueva más\n",
    "* $C\\rightarrow S:$ $\\;$ en época de lluvias los aspersores se ponen menos\n",
    "* $R\\rightarrow W:$ $\\;$ la lluvia humedece la hierba\n",
    "* $S\\rightarrow W:$ $\\;$ los aspersores están en marcha humedecen la hierba\n",
    "\n",
    "**Distribución conjunta:** $\\;$ con independencias tachadas\n",
    "$$p(C,S,R,W)=p(C)\\,p(S\\mid C)\\,p(R\\mid C,\\cancel{S})\\,p(W\\mid S,R,\\cancel{C})$$\n",
    "\n",
    "<div align=center><img src=\"Figure_3.14.png\" width=600></div>\n",
    "\n",
    "**Distribución de probabilidad condicional (CPD):** $\\;p(Y_i\\mid\\mathbf{Y}_{\\operatorname{pa}(i)})$\n",
    "\n",
    "**Tabla de probabilidad condicional (CPT):** $\\;$ si $Y_i$ es categórica\n",
    "\n",
    "**Representación de una CPT:** $\\;\\{\\theta_{ijk}\\}$\n",
    "$$\\theta_{ijk}=p(Y_i=k\\mid\\mathbf{Y}_{\\operatorname{pa}(i)}=j)$$\n",
    "\n",
    "* *Propiedades:* $\\;0\\leq\\theta_{ijk}\\leq 1\\;$ y $\\;\\sum_{k=1}^K\\theta_{ijk}=1$\n",
    "* $i$ indexa nodos, $i\\in[V]$\n",
    "* $k$ indexa estados de nodos, $k\\in[K_i]$, con $K_i$ estados del $i$\n",
    "* $j$ indexa estados de padres conjuntos, $j\\in[J_i]$, $J_i=\\prod_{p\\in\\operatorname{pa}(i)}K_p$\n",
    "* *Ejemplo:* $\\;$ el nodo $W$ tiene dos padres binarios, esto es, cuatro estados padre\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1.2 Ejemplo: cadena de Markov\n",
    "\n",
    "**Modelo de lenguaje:** $\\;$ distribución de probabilidad sobre secuencias de longitud variable, $p(y_{1:T})$, donde cada $y_t$ representa una palabra de un vocabulario con $K$ posibles valores, $y_t\\in\\{1,\\dotsc,K\\}$\n",
    "\n",
    "**Distribución conjunta sobre $T$ variables:** $\\;$ regla de la cadena\n",
    "$$p(\\boldsymbol{y}_{1:T})=p(y_1)\\,p(y_2\\mid y_1)\\,p(y_3\\mid y_2,y_1)\\,p(y_4\\mid y_3,y_2,y_1)\\ldots=\\prod_{t=1}^Tp(y_t\\mid \\boldsymbol{y}_{1:t-1})$$\n",
    "\n",
    "**Número de parámetros inmanejable:** $\\;$ el número de parámetros para representar cada distribución condicional $p(y_t\\mid\\boldsymbol{y}_{1:t-1})$ crece exponencialmente con $t$\n",
    "\n",
    "**Condición de Markov de primer orden:** $\\;$ futuro $\\boldsymbol{y}_{t+1:T}$ independiente del pasado, $\\boldsymbol{y}_{1:t-1}$, dado el presente, $y_t$\n",
    "$$p(\\boldsymbol{y}_{1:T})=p(y_1)\\,p(y_2\\mid y_1)\\,p(y_3\\mid y_2)\\ldots=p(y_1)\\prod_{t=2}^Tp(y_t\\mid y_{t-1})$$\n",
    "<div align=center><img src=\"Figure_3.15_A.png\" width=400></div>\n",
    "\n",
    "### Cadena o modelo de Markov de primer orden\n",
    "\n",
    "**Función o kernel de transición, o kernel Markov:** $\\;p(y_t\\mid y_{t-1})$\n",
    "\n",
    "**Propiedades:** $\\;p(y_t\\mid y_{t.1})\\geq 0\\;$ y $\\;\\sum_{k=1}^Kp(y_t=k\\mid y_{t-1}=j)=1$\n",
    "\n",
    "**Matriz de transición entre estados:** $\\;A_{jk}=p(y_t=k\\mid y_{t-1}=j)$\n",
    "\n",
    "**Modelo homogéneo, estacionario o invariante en tiempo:** $\\;$ ligamos parámetros de múltiples variables para modelizarlas con un número fijo de parámetros\n",
    "\n",
    "### Cadena o modelo de Markov de orden M\n",
    "\n",
    "**Modelo de Markov de orden M:** $\\;$ con memoria de longitud $M$\n",
    "$$p(\\boldsymbol{y}_{1:T})=p(\\boldsymbol{y}_{1:M})\\prod_{t=M+1}^Tp(y_t\\mid y_{t-M:t-1})$$\n",
    "\n",
    "**Bigrama:** $\\;$ modelo de Markov convencional, con $M=1$\n",
    "\n",
    "**Trigrama:** $\\;M=2$\n",
    "<div align=center><img src=\"Figure_3.15_B.png\" width=400></div>\n",
    "\n",
    "**M gramas:** $\\;$ con $M>2$ y vocabularios grandes, las CPTs se aproximan mediante matrices de bajo rango o redes neuronales"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
