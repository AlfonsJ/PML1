{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2.3 Conexión entre LDA y regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**LDA y regresión logística coinciden en modelo:** $\\;$ posterior log-lineal con la entrada\n",
    "$$p(y=c\\mid\\boldsymbol{x},\\boldsymbol{\\theta})%\n",
    "\\propto\\exp(\\boldsymbol{\\beta}_c^t\\boldsymbol{x}+\\gamma_c)%\n",
    "\\quad\\text{con}\\quad%\n",
    "\\boldsymbol{\\beta}_c=\\mathbf{\\Sigma}^{-1}\\boldsymbol{\\mu}_c%\n",
    "\\quad\\text{y}\\quad%\n",
    "\\gamma_c=\\log\\pi_c-\\frac{1}{2}\\boldsymbol{\\mu}_c^t\\mathbf{\\Sigma}^{-1}\\boldsymbol{\\mu}_c$$\n",
    "\n",
    "**LDA y regresión logística difieren en el criterio de entrenamiento:**\n",
    "* LDA se entrena optimizando la verosimilitud conjunta, $\\;\\prod_n p(y_n, \\boldsymbol{x}_n, \\boldsymbol{\\theta})$\n",
    "* Regresión logística se entrena optimizando la verosimilitud condicional, $\\;\\prod_n p(y_n\\mid\\boldsymbol{x}_n, \\boldsymbol{\\theta})$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso binario\n",
    "\n",
    "En el caso $c\\in\\{0,1\\}$, es fácil comprobar que LDA coincide con regresión logística binaria:\n",
    "$$\\begin{align*}\n",
    "p(y=1\\mid\\boldsymbol{x},\\boldsymbol{\\theta})&=\\frac{\\exp(\\boldsymbol{\\beta}_1^t\\boldsymbol{x}+\\gamma_1)}{\\exp(\\boldsymbol{\\beta}_1^t\\boldsymbol{x}+\\gamma_1)+\\exp(\\boldsymbol{\\beta}_0^t\\boldsymbol{x}+\\gamma_0)}=\\sigma(\\boldsymbol{w}^t(\\boldsymbol{x}-\\boldsymbol{x}_0))\\\\[5mm]%\n",
    "\\boldsymbol{w}&=\\boldsymbol{\\beta}_1-\\boldsymbol{\\beta}_0=\\mathbf{\\Sigma}^{-1}(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_0)\\\\%\n",
    "\\boldsymbol{x}_0&=\\frac{1}{2}(\\boldsymbol{\\mu}_1+\\boldsymbol{\\mu}_0)-(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_0)\\frac{\\log(\\pi_1/\\pi_0)}{(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_0)^t\\mathbf{\\Sigma}^{-1}(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_0)}\n",
    "\\end{align*}$$\n",
    "Por tanto, la regla de decisión MAP puede escribirse como:\n",
    "$$\\hat{y}(\\boldsymbol{x})=1\\quad\\text{sii}\\quad%\n",
    "\\boldsymbol{w}^t\\boldsymbol{x}>\\boldsymbol{w}^t\\boldsymbol{x}_0$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:** $\\;$ si $\\;\\pi_0=\\pi_1=0.5\\;$ y $\\;\\mathbf{\\Sigma}=\\sigma^2\\mathbf{I}$, entonces $\\;\\boldsymbol{w}=\\sigma^{-2}(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_0)\\;$ y MAP comprueba si la proyección de $\\boldsymbol{x}$ en la dirección $(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_0)$ es mayor que la mitad de la distancia entre $\\boldsymbol{\\mu}_0$ y $\\boldsymbol{\\mu}_1$\n",
    "$$\\boldsymbol{w}^t\\boldsymbol{x}>\\boldsymbol{w}^t\\boldsymbol{x}_0%\n",
    "\\quad\\text{sii}\\quad%%\n",
    "(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_0)^t\\boldsymbol{x}>(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_0)^t\\boldsymbol{x}_0%\n",
    "\\quad\\text{con}\\quad%%\n",
    "\\boldsymbol{x}_0=\\frac{1}{2}(\\boldsymbol{\\mu}_1+\\boldsymbol{\\mu}_0)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
